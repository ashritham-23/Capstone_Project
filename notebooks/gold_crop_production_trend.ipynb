{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db0c4cf2-1f76-442b-b9fb-092421c14279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "GOLD LAYER – ANALYTICS TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5f56b0-4aa7-40f9-ae69-b1c56ca01a23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.empty-table+json": {
       "directive_name": "NoDirective"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "USE CATALOG main;\n",
    "USE SCHEMA agriculture_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "395e864a-6e57-4c13-a8bd-b10bc927aa0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Crop Production Trend (with Weather Impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b6a282b-f7df-4094-87e3-587f95109435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use agriculture database\n",
    "spark.sql(\"USE agriculture_data\")\n",
    "\n",
    "from pyspark.sql.functions import sum, avg, col\n",
    "\n",
    "# Load silver tables\n",
    "crop_df = spark.table(\"silver_crop_production\")\n",
    "weather_df = spark.table(\"silver_weather\")\n",
    "\n",
    "# Join crop data with weather data\n",
    "gold_crop_weather_trend = (\n",
    "    crop_df\n",
    "    .join(\n",
    "        weather_df,\n",
    "        on=[\"state\", \"district\", \"year\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .groupBy(\"crop\", \"year\")\n",
    "    .agg(\n",
    "        sum(\"production_tonnes\").alias(\"total_production\"),\n",
    "        sum(\"area_hectares\").alias(\"total_area\"),\n",
    "        avg(\"avg_rainfall_mm\").alias(\"avg_rainfall\")\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bb93577-cae8-4564-8a55-f792deebdea2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gold – Logging – crop_weather_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd330541-c5a8-4586-85ad-ac676e8a78b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    StringType, LongType, TimestampType\n",
    ")\n",
    "from pyspark.sql.functions import current_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116b3bfe-6dc7-4205-96f2-b6b170d93e2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "log_schema = StructType([\n",
    "    StructField(\"pipeline_name\", StringType(), True),\n",
    "    StructField(\"layer\", StringType(), True),\n",
    "    StructField(\"table_name\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"record_count\", LongType(), True),\n",
    "    StructField(\"start_time\", TimestampType(), True),\n",
    "    StructField(\"end_time\", TimestampType(), True),\n",
    "    StructField(\"error_message\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4e685b5-18b6-45d5-befd-c0fc341672ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logging metadata\n",
    "pipeline_name = \"agriculture_pipeline\"\n",
    "layer = \"GOLD\"\n",
    "table_name = \"gold_crop_weather_trend\"\n",
    "\n",
    "try:\n",
    "    # Record count after aggregation\n",
    "    record_count = gold_crop_weather_trend.count()\n",
    "\n",
    "    # Write gold table\n",
    "    gold_crop_weather_trend.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(table_name)\n",
    "\n",
    "    # Success log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"SUCCESS\", record_count, None, None, None)],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Failure log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"FAILED\", None, None, None, str(e))],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1bb1c8-84ff-4e34-a88d-42aad4c3f83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid production records: 0\n"
     ]
    }
   ],
   "source": [
    "# Production Validation\n",
    "\n",
    "# Validate aggregated production values in gold table\n",
    "invalid_production_records = gold_crop_weather_trend.filter(\n",
    "    col(\"total_production\") <= 0\n",
    ").count()\n",
    "\n",
    "print(f\"Invalid production records: {invalid_production_records}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f35d958-a9c7-4a5e-98f4-6f4de3d925a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Regional Yield with Soil Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88fa8729-2b12-4ed3-b8fa-79fde061fdeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use agriculture database\n",
    "spark.sql(\"USE agriculture_data\")\n",
    "\n",
    "# Load silver tables\n",
    "crop_df = spark.table(\"silver_crop_production\")\n",
    "soil_df = spark.table(\"silver_soil_health\")\n",
    "\n",
    "# Join crop production with soil health\n",
    "gold_region_soil_yield = (\n",
    "    crop_df\n",
    "    .join(\n",
    "        soil_df,\n",
    "        on=[\"state\", \"district\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .groupBy(\"state\", \"district\")\n",
    "    .agg(\n",
    "        avg(\"yield_tonnes_per_hectare\").alias(\"avg_yield\"),\n",
    "        avg(\"ph_level\").alias(\"avg_soil_ph\"),\n",
    "        avg(\"nitrogen\").alias(\"avg_nitrogen\")\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceea7758-ddcf-4f95-9552-7057e4d67d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gold – Logging – region_soil_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340767eb-7d97-4008-ba00-64b2b839eb4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logging metadata\n",
    "pipeline_name = \"agriculture_pipeline\"\n",
    "layer = \"GOLD\"\n",
    "table_name = \"gold_region_soil_yield\"\n",
    "\n",
    "try:\n",
    "    # Record count after aggregation\n",
    "    record_count = gold_region_soil_yield.count()\n",
    "\n",
    "    # Write gold table\n",
    "    gold_region_soil_yield.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(table_name)\n",
    "\n",
    "    # Success log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"SUCCESS\", record_count, None, None, None)],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Failure log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"FAILED\", None, None, None, str(e))],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44376d14-ffbb-4176-a43f-41494653de37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Seasonal Yield with Market Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d3fe59f-0f81-4298-aea9-9be49a66de26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use agriculture database\n",
    "spark.sql(\"USE agriculture_data\")\n",
    "\n",
    "# Load silver tables\n",
    "crop_df = spark.table(\"silver_crop_production\")\n",
    "market_df = spark.table(\"silver_market_prices\")\n",
    "\n",
    "# Join crop production with market prices\n",
    "gold_season_market_analysis = (\n",
    "    crop_df\n",
    "    .join(\n",
    "        market_df,\n",
    "        on=[\"crop\", \"year\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .groupBy(\"season\", \"year\")\n",
    "    .agg(\n",
    "        avg(\"yield_tonnes_per_hectare\").alias(\"avg_yield\"),\n",
    "        sum(\"production_tonnes\").alias(\"total_production\"),\n",
    "        avg(\"market_price_per_quintal\").alias(\"avg_market_price\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "200280d1-8819-4995-8335-90f4094b999d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gold – Logging – season_market_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4825b6d-04a0-4ab0-805c-ddb9d828a2cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logging metadata\n",
    "pipeline_name = \"agriculture_pipeline\"\n",
    "layer = \"GOLD\"\n",
    "table_name = \"gold_season_market_analysis\"\n",
    "\n",
    "try:\n",
    "    # Record count after aggregation\n",
    "    record_count = gold_season_market_analysis.count()\n",
    "\n",
    "    # Write gold table\n",
    "    gold_season_market_analysis.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(table_name)\n",
    "\n",
    "    # Success log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"SUCCESS\", record_count, None, None, None)],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Failure log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"FAILED\", None, None, None, str(e))],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d5e772-1b91-4286-8ede-b5d2135b187f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gold Agriculture Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab59841e-0aed-4304-b44d-5f5e6f48821c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use agriculture database\n",
    "spark.sql(\"USE agriculture_data\")\n",
    "\n",
    "# Gold table 1: Crop + Weather\n",
    "crop_weather_df = (\n",
    "    spark.table(\"gold_crop_weather_trend\")\n",
    "    .withColumnRenamed(\"total_production\", \"crop_total_production\")\n",
    "    .withColumnRenamed(\"total_area\", \"crop_total_area\")\n",
    ")\n",
    "\n",
    "# Gold table 2: Region + Soil\n",
    "region_soil_df = (\n",
    "    spark.table(\"gold_region_soil_yield\")\n",
    "    .withColumnRenamed(\"avg_yield\", \"region_avg_yield\")\n",
    ")\n",
    "\n",
    "# Gold table 3: Season + Market\n",
    "season_market_df = (\n",
    "    spark.table(\"gold_season_market_analysis\")\n",
    "    .withColumnRenamed(\"avg_yield\", \"season_avg_yield\")\n",
    "    .withColumnRenamed(\"total_production\", \"season_total_production\")\n",
    ")\n",
    "\n",
    "# Create final summary table (lineage anchor)\n",
    "final_gold_summary = (\n",
    "    crop_weather_df\n",
    "    .join(season_market_df, on=\"year\", how=\"left\")\n",
    "    .join(region_soil_df, how=\"cross\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c02bd752-24f0-485f-a5e4-33fd0f3246c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gold – Logging – agriculture_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f184d501-821c-4100-9986-915394f6d613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Logging metadata\n",
    "pipeline_name = \"agriculture_pipeline\"\n",
    "layer = \"GOLD\"\n",
    "table_name = \"gold_agriculture_summary\"\n",
    "\n",
    "try:\n",
    "    # Record count after final aggregation\n",
    "    record_count = final_gold_summary.count()\n",
    "\n",
    "    # Write final gold summary table\n",
    "    final_gold_summary.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(table_name)\n",
    "\n",
    "    # Success log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"SUCCESS\", record_count, None, None, None)],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Failure log\n",
    "    log_df = spark.createDataFrame(\n",
    "        [(pipeline_name, layer, table_name, \"FAILED\", None, None, None, str(e))],\n",
    "        schema=log_schema\n",
    "    )\n",
    "\n",
    "    log_df = log_df.withColumn(\"start_time\", current_timestamp()) \\\n",
    "                   .withColumn(\"end_time\", current_timestamp())\n",
    "\n",
    "    log_df.write.format(\"delta\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"agriculture_data.pipeline_logs\")\n",
    "\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdd313cd-42e5-49c4-94d7-e1219da810fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "View Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edb864b6-c62a-499d-9a24-c2fa746eb102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---------------------------+------------+-------+-------------+--------------------------+--------------------------+-------------+\n|pipeline_name       |layer |table_name                 |record_count|status |run_timestamp|start_time                |end_time                  |error_message|\n+--------------------+------+---------------------------+------------+-------+-------------+--------------------------+--------------------------+-------------+\n|agriculture_pipeline|GOLD  |gold_agriculture_summary   |126000      |SUCCESS|NULL         |2026-01-05 15:28:20.250734|2026-01-05 15:28:20.250734|NULL         |\n|agriculture_pipeline|GOLD  |gold_season_market_analysis|45          |SUCCESS|NULL         |2026-01-05 15:28:08.756492|2026-01-05 15:28:08.756492|NULL         |\n|agriculture_pipeline|GOLD  |gold_region_soil_yield     |400         |SUCCESS|NULL         |2026-01-05 15:27:58.698306|2026-01-05 15:27:58.698306|NULL         |\n|agriculture_pipeline|GOLD  |gold_crop_weather_trend    |105         |SUCCESS|NULL         |2026-01-05 15:27:44.231364|2026-01-05 15:27:44.231364|NULL         |\n|agriculture_pipeline|SILVER|silver_market_prices       |10000       |SUCCESS|NULL         |2026-01-05 15:27:19.000668|2026-01-05 15:27:19.000668|NULL         |\n|agriculture_pipeline|SILVER|silver_soil_health         |400         |SUCCESS|NULL         |2026-01-05 15:27:06.369583|2026-01-05 15:27:06.369583|NULL         |\n|agriculture_pipeline|SILVER|silver_weather             |4901        |SUCCESS|NULL         |2026-01-05 15:26:49.165778|2026-01-05 15:26:49.165778|NULL         |\n|agriculture_pipeline|SILVER|silver_crop_production     |10000       |SUCCESS|NULL         |2026-01-05 15:26:34.812719|2026-01-05 15:26:34.812719|NULL         |\n|agriculture_pipeline|BRONZE|bronze_market_prices       |10000       |SUCCESS|NULL         |2026-01-05 15:25:54.557153|2026-01-05 15:25:54.557153|NULL         |\n|agriculture_pipeline|BRONZE|bronze_soil_health         |10000       |SUCCESS|NULL         |2026-01-05 15:25:45.46648 |2026-01-05 15:25:45.46648 |NULL         |\n|agriculture_pipeline|BRONZE|bronze_weather             |10000       |SUCCESS|NULL         |2026-01-05 15:25:10.136113|2026-01-05 15:25:10.136113|NULL         |\n|agriculture_pipeline|BRONZE|bronze_crop_production     |10000       |SUCCESS|NULL         |2026-01-05 15:24:52.175982|2026-01-05 15:24:52.175982|NULL         |\n|agriculture_pipeline|GOLD  |gold_agriculture_summary   |126000      |SUCCESS|NULL         |2026-01-05 11:39:36.179727|2026-01-05 11:39:36.179727|NULL         |\n|agriculture_pipeline|GOLD  |gold_season_market_analysis|45          |SUCCESS|NULL         |2026-01-05 11:39:30.800792|2026-01-05 11:39:30.800792|NULL         |\n|agriculture_pipeline|GOLD  |gold_region_soil_yield     |400         |SUCCESS|NULL         |2026-01-05 11:39:26.332843|2026-01-05 11:39:26.332843|NULL         |\n|agriculture_pipeline|GOLD  |gold_crop_weather_trend    |105         |SUCCESS|NULL         |2026-01-05 11:39:19.876378|2026-01-05 11:39:19.876378|NULL         |\n|agriculture_pipeline|SILVER|silver_market_prices       |10000       |SUCCESS|NULL         |2026-01-05 11:38:42.202687|2026-01-05 11:38:42.202687|NULL         |\n|agriculture_pipeline|SILVER|silver_soil_health         |400         |SUCCESS|NULL         |2026-01-05 11:38:29.382171|2026-01-05 11:38:29.382171|NULL         |\n|agriculture_pipeline|SILVER|silver_weather             |4901        |SUCCESS|NULL         |2026-01-05 11:38:24.256105|2026-01-05 11:38:24.256105|NULL         |\n|agriculture_pipeline|SILVER|silver_crop_production     |10000       |SUCCESS|NULL         |2026-01-05 11:38:18.26384 |2026-01-05 11:38:18.26384 |NULL         |\n+--------------------+------+---------------------------+------------+-------+-------------+--------------------------+--------------------------+-------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PIPELINE LOG VIEW \n",
    "\n",
    "logs_df = spark.table(\"agriculture_data.pipeline_logs\")\n",
    "logs_df.orderBy(\"start_time\", ascending=False).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5062203471271729,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_crop_production_trend",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}